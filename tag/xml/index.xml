<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>XML | Digital Egyptian Gazette</title><link>https://dig-eg-gaz.github.io/tag/xml/</link><atom:link href="https://dig-eg-gaz.github.io/tag/xml/index.xml" rel="self" type="application/rss+xml"/><description>XML</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sun, 27 Nov 2016 00:00:00 +0000</lastBuildDate><image><url>https://dig-eg-gaz.github.io/media/icon_hu3ccbb7e8d76090b34f602b231dc00fc8_804790_512x512_fill_lanczos_center_3.png</url><title>XML</title><link>https://dig-eg-gaz.github.io/tag/xml/</link></image><item><title>XML Brings Tears</title><link>https://dig-eg-gaz.github.io/post/2016-11-27-ifs-blog-post-2-daisy/</link><pubDate>Sun, 27 Nov 2016 00:00:00 +0000</pubDate><guid>https://dig-eg-gaz.github.io/post/2016-11-27-ifs-blog-post-2-daisy/</guid><description>&lt;p>During the fall semester, I have been introduced to a variety of coding programs I have never known about or used and it has been a process to adjust. Starting from scanning all the images present from my week of research in the Egyptian Gazette, to currently working with XML/TEI programs to edit the text files of our Egyptian Gazette image files, to adding, ranging from tagging to adjusting grammar errors. It has been a tedious experience, especially with editing the text files on ABBYY Finereader 12 initially, fixing the errors of every word per page. The program found several errors for each page, so the process to edit was time consuming. However, after moving forward to the XML program, I can say I prefer XML/TEI programming over the ABBYY Finereader 12. This is because I am to look more into the text and learn more information, versus fixing grammar mistakes. With XML, reading the Egyptian Gazette is much easier because the program organizes the text with taggings such as &lt;code>&amp;lt;div&amp;gt;, &amp;lt;head&amp;gt;, &amp;lt;placeName&amp;gt;, &amp;lt;p&amp;gt;&lt;/code>, and a variety of other tagging methods I have not even used yet. All in all, this exposure to online sources, such as using Github, XML, ABBYY, and probably more has been the most stressful experience in time management this semester. Pray for my survival. RIP.&lt;/p></description></item><item><title>Time Issues</title><link>https://dig-eg-gaz.github.io/post/2016-11-07-hofmeister-time-issues/</link><pubDate>Mon, 07 Nov 2016 00:00:00 +0000</pubDate><guid>https://dig-eg-gaz.github.io/post/2016-11-07-hofmeister-time-issues/</guid><description>&lt;p>To be honest, this class is not what I expected it to be. I did not expect
to be learning how to code things or doing xml or anything that involved
technical skills. While learning the skills is not difficult, it is
difficult to find the time it takes to complete the assignments.
I try to set aside time to complete pages and to edit the text,
however I can never find enough time. For me, this is a huge issue
because I am super obsessive about my grades and I am actually
concerned about not receiving a good grade in this class. I do not face
any technical issues, just time issues. Thus far I have completed the first
three pages of everyday , the only issue in the pages that I find is not
being able to read the data for financial tables. The data is always written
very small and it tends to be smudged and &lt;strong>I hate it and it gives me a headache.&lt;/strong>&lt;/p></description></item><item><title>Haskell and XML</title><link>https://dig-eg-gaz.github.io/post/2016-11-06-haskell-and-xml/</link><pubDate>Sun, 06 Nov 2016 00:00:00 +0000</pubDate><guid>https://dig-eg-gaz.github.io/post/2016-11-06-haskell-and-xml/</guid><description>&lt;p>I got pretty bored performing the same search-and-replace actions for a variety of different place names. As any programmer knows, performing the same actions over and over again signals a perfect opportunity to use code to script out those actions.&lt;/p>
&lt;p>I spent time this weekend investigating the possibility of using Haskell to write a script to automatically TEI index certain words with tags and reference data.&lt;/p>
&lt;p>The program (which would be a command-line utility at first) needs to perform a few basic functions:&lt;/p>
&lt;ol>
&lt;li>Add tags to text inside any xml nodes&lt;/li>
&lt;li>Update attributes of tags with specified contents&lt;/li>
&lt;li>Take in input file that describes a set of commands&lt;/li>
&lt;/ol>
&lt;p>This would potentially allow me to update every xml file in the entire repository simultaneously, inserting the proper tags for a list of names, dates, and locations. Something like:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-yaml" data-lang="yaml">&lt;span class="line">&lt;span class="cl">&lt;span class="nt">placename&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>- &lt;span class="l">(Tokyo, ref, some-link-to-wikidata)&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>- &lt;span class="l">(London, ref, some-link-to-wikidata)&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>- &lt;span class="l">(St. Petersburg, ref, some-link-to-wikidata)&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>- &lt;span class="l">(Port Said, ref, some-link-to-wikidata)&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="nt">persname&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>- &lt;span class="l">(Lord Cromer, ref, some-link-to-person-data)&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This would allow me to just keep an up-to-date set of location names, attribute names, and links that I could then very easily update or apply to any issue in the entire year, and perhaps even set it to run every time I changed a file, so I would never have to worry about manually changing this information.&lt;/p>
&lt;h2 id="a-quick-note-on-xml">A quick note on XML&lt;/h2>
&lt;p>XML can be visualized as a &amp;ldquo;rose tree&amp;rdquo; made of nodes. This basically means that every part of the XML document is some sort of node, which has other nodes inside of it. The nodes can be any type of tag, or any plain text, and any number of both in any order.&lt;/p>
&lt;p>Here&amp;rsquo;s what some XML in your issue might look like as a Tree&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">div -*- dateline -*- date - Text
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> | *- Text
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> | *- placename - Text
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> |
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> *- p - Text
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> *- byline - Text
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>And here it is as XML&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-XML" data-lang="XML">&lt;span class="line">&lt;span class="cl">&lt;span class="nt">&amp;lt;div&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;lt;dateline&amp;gt;&amp;lt;date&amp;gt;&lt;/span>2nd October 1905&lt;span class="nt">&amp;lt;/date&amp;gt;&lt;/span>, &lt;span class="nt">&amp;lt;placename&amp;gt;&lt;/span>Port Said&lt;span class="nt">&amp;lt;/placename&amp;gt;&amp;lt;/dateline&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;lt;p&amp;gt;&lt;/span>Here is some text, detailing an amazing story about something.&lt;span class="nt">&amp;lt;/p&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nt">&amp;lt;byline&amp;gt;&lt;/span>(Reuter.)&lt;span class="nt">&amp;lt;/byline&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nt">&amp;lt;/div&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="functional-programming">Functional Programming&lt;/h2>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://www.haskell.org/static/img/haskell-logo.svg?etag=ukf3Fg7-" alt="Haskell Logo" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>I program in Haskell mostly. Haskell is a pure functional language, which just means it&amp;rsquo;s not the same as the traditional programming languages you see day-to-day, and it&amp;rsquo;s not something FSU teaches currently.&lt;/p>
&lt;p>It looks something like this:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-Haskell" data-lang="Haskell">&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nf">and&lt;/span> &lt;span class="ow">::&lt;/span> &lt;span class="kt">Bool&lt;/span> &lt;span class="ow">-&amp;gt;&lt;/span> &lt;span class="kt">Bool&lt;/span> &lt;span class="ow">-&amp;gt;&lt;/span> &lt;span class="kt">Bool&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nf">and&lt;/span> &lt;span class="n">c&lt;/span> &lt;span class="n">t&lt;/span> &lt;span class="ow">=&lt;/span> &lt;span class="kr">if&lt;/span> &lt;span class="n">c&lt;/span> &lt;span class="kr">then&lt;/span> &lt;span class="n">t&lt;/span> &lt;span class="kr">else&lt;/span> &lt;span class="kt">False&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nf">filter&lt;/span> &lt;span class="ow">::&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">a&lt;/span> &lt;span class="ow">-&amp;gt;&lt;/span> &lt;span class="kt">Bool&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="ow">-&amp;gt;&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="n">a&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="ow">-&amp;gt;&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="n">a&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nf">filter&lt;/span> &lt;span class="n">p&lt;/span> &lt;span class="n">xs&lt;/span> &lt;span class="ow">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="n">x&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="n">x&lt;/span> &lt;span class="ow">&amp;lt;-&lt;/span> &lt;span class="n">xs&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">p&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nf">map&lt;/span> &lt;span class="ow">::&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">a&lt;/span> &lt;span class="ow">-&amp;gt;&lt;/span> &lt;span class="n">b&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="ow">-&amp;gt;&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="n">a&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="ow">-&amp;gt;&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="n">b&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nf">map&lt;/span> &lt;span class="kr">_&lt;/span> &lt;span class="kt">[]&lt;/span> &lt;span class="ow">=&lt;/span> &lt;span class="kt">[]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nf">map&lt;/span> &lt;span class="n">f&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="kt">:&lt;/span>&lt;span class="n">xs&lt;/span> &lt;span class="ow">=&lt;/span> &lt;span class="n">f&lt;/span> &lt;span class="n">x&lt;/span> &lt;span class="kt">:&lt;/span> &lt;span class="n">map&lt;/span> &lt;span class="n">xs&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>It&amp;rsquo;s pretty rad, it looks quite unlike most languages I&amp;rsquo;ve seen in my day. Haskell has some really interesting properties, though. It&amp;rsquo;s really easy to parse documents as a result, but it&amp;rsquo;s difficult to transform them easily. Many libraries exist to extract data easily and reliably from xml documents, but few to transform or modify them in a programatic way.&lt;/p>
&lt;p>I did find one eventually: the &lt;a href="https://wiki.haskell.org/HXT" target="_blank" rel="noopener">Haskell XML Toolbox&lt;/a>. It lets you do some pretty interesting things. It uses something called arrows (a &lt;em>very&lt;/em> trippy functional programming concept), to allow the programmer to compose filters together to navigate the XML tree.&lt;/p>
&lt;p>The &lt;a href="https://wiki.haskell.org/HXT#The_concept_of_filters" target="_blank" rel="noopener">documentation&lt;/a> has this example:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-Haskell" data-lang="Haskell">&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nf">isA&lt;/span> &lt;span class="ow">::&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">a&lt;/span> &lt;span class="ow">-&amp;gt;&lt;/span> &lt;span class="kt">Bool&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="ow">-&amp;gt;&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">a&lt;/span> &lt;span class="ow">-&amp;gt;&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="n">a&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nf">isA&lt;/span> &lt;span class="n">p&lt;/span> &lt;span class="n">x&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="n">p&lt;/span> &lt;span class="n">x&lt;/span> &lt;span class="ow">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">|&lt;/span> &lt;span class="n">otherwise&lt;/span> &lt;span class="ow">=&lt;/span> &lt;span class="kt">[]&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>It takes a function (called a predicate) that returns a True/False value, and creates a new function that can process, or filter, values. Essentially, these arrows let us process parts of a tree into no results, one result, or many results. By using different types of filters, and by putting these filters together, with some relatively simple structure we can create some &lt;em>extremely&lt;/em> complex instructions to parse and transform the document.&lt;/p>
&lt;p>Again, an example from the documentation:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-Haskell" data-lang="Haskell">&lt;span class="line">&lt;span class="cl">&lt;span class="nf">getGrandChildren&lt;/span> &lt;span class="ow">::&lt;/span> &lt;span class="kt">XmlFilter&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nf">getGrandChildren&lt;/span> &lt;span class="ow">=&lt;/span> &lt;span class="n">getChildren&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">getChildren&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The &lt;code>(&amp;gt;&amp;gt;&amp;gt;)&lt;/code> operator makes it extremely trivial to chain filters together to make new filters. The ability to compose functions like this is the hallmark of functional programming, and works extremely well in this case.&lt;/p>
&lt;p>By defining a few more combination operators, the HXT library quickly builds up sufficient capability to tackle some really complicated parsing, as in:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-Haskell" data-lang="Haskell">&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nf">getTextChildren2&lt;/span> &lt;span class="ow">::&lt;/span> &lt;span class="kt">XmlFilter&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nf">getTextChildren2&lt;/span> &lt;span class="ow">=&lt;/span> &lt;span class="n">getChildren&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span class="p">(&lt;/span> &lt;span class="n">isXText&lt;/span> &lt;span class="o">&amp;lt;+&amp;gt;&lt;/span> &lt;span class="p">(&lt;/span> &lt;span class="n">getChildren&lt;/span> &lt;span class="o">&amp;gt;&amp;gt;&amp;gt;&lt;/span> &lt;span class="n">isXText&lt;/span> &lt;span class="p">)&lt;/span> &lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>which only gets the text children for of the current tag, and the text of any tags inside the current one.&lt;/p>
&lt;p>Using this extremely flexible library, I hope to find a practical way to automate much of the task of TEI indexing the Egyptian Gazette!&lt;/p></description></item><item><title>Technical Reflection</title><link>https://dig-eg-gaz.github.io/post/2016-10-25-stefonek-technical-reflection/</link><pubDate>Tue, 25 Oct 2016 00:00:00 +0000</pubDate><guid>https://dig-eg-gaz.github.io/post/2016-10-25-stefonek-technical-reflection/</guid><description>&lt;p>I suppose I&amp;rsquo;ll start off with how much I&amp;rsquo;ve learned so far through this course; taking digital images of film, running text recognition software, writing in Markdown and encoding in XML. Though it has all been incredibly interesting and fulfilling, the mention of those words along with &lt;a href="https://dig-eg-gaz.github.io/" target="_blank" rel="noopener">&amp;ldquo;Digital Egyptian Gazette&amp;rdquo;&lt;/a>, will likely send chills down my spine for quite a while.&lt;/p>
&lt;p>To start, my largest technical obstacle was the poor job done by Fine Reader. While it truly saved me a lot of time by translating the text, it also made an overwhelming amount of errors that are incredibly time-consuming and painstaking to correct. If I were to make an estimate, correcting and encoding one page of the newspaper takes about three and a half hours. Aside from that I have had trouble with putting together the tables and advertisements in my week. Several of them do not yet exist as text files that I can pull from and for the ones that I do have access to, it takes about three copy and pastes before I trigger an &amp;ldquo;abuse mechanism&amp;rdquo; on GitHub. This locks me out for a couple of minutes before I can get back to work. But regardless, we push onward!&lt;/p></description></item><item><title>Technical Difficulties in the Egyptian Gazette</title><link>https://dig-eg-gaz.github.io/post/2016-10-06-technical-difficulties-in-ocr/</link><pubDate>Thu, 06 Oct 2016 00:00:00 +0000</pubDate><guid>https://dig-eg-gaz.github.io/post/2016-10-06-technical-difficulties-in-ocr/</guid><description>&lt;p>When I first produced my image scans using the library&amp;rsquo;s microfilm
of the Egyptian Gazette, I thought that by feeding the material into
the OCR software, my computer would automatically spit back the
entire transcription completed error-free. At first I attempted to use
FineReader on my roommate&amp;rsquo;s laptop, hoping it would yield results, but
when her computer began to lag and I realized how time consuming the
process would be, I switched to using my Mac.&lt;/p>
&lt;p>When the class discovered Cisdem PDF Converter for Mac, I quickly
realized that while some pages contained minimal errors, others required
extensive corrections to yield an accurate reading of the text.
The pages, most of which were rife with errors, took around 2 and a half
hours each to fully type and XML, and even then many advertisements and
charts are still not completed.&lt;/p>
&lt;p>After I had completed the vast majority of the transcription, I learned
that by scanning in a higher resolution and stitching multiple images
together, I probably could have produced the paper and a much faster rate.&lt;/p>
&lt;p>Nevertheless, I&amp;rsquo;m continuing to work on completing certain advertisements
and charts, as well as TEI-tagging people and places.&lt;/p></description></item></channel></rss>